{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <strong>GENERE PREDICTING MACHINE LEARNING MODEL</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HELLO EVERYONE. In this session, we will see how we can classify a genere of a movie based on it's plot summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our dataset is IMDB movie classification data from kaggle. We will use many classification models like naive bayes, SVM, logerstic regression and random forest. We will compare the accuracies of each model at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>Let's make the necessary imports</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Eyosi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Eyosi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Eyosi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load our data. Our data has training part, testing part and also test solution part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>GENRE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oscar et la dame rose (2009)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Listening in to a conversation between his do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cupid (1997)</td>\n",
       "      <td>thriller</td>\n",
       "      <td>A brother and sister with a past incestuous r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Young, Wild and Wonderful (1980)</td>\n",
       "      <td>adult</td>\n",
       "      <td>As the bus empties the students for their fie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Secret Sin (1915)</td>\n",
       "      <td>drama</td>\n",
       "      <td>To help their unemployed father make ends mee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Unrecovered (2007)</td>\n",
       "      <td>drama</td>\n",
       "      <td>The film's title refers not only to the un-re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                               TITLE       GENRE  \\\n",
       "0   1       Oscar et la dame rose (2009)       drama    \n",
       "1   2                       Cupid (1997)    thriller    \n",
       "2   3   Young, Wild and Wonderful (1980)       adult    \n",
       "3   4              The Secret Sin (1915)       drama    \n",
       "4   5             The Unrecovered (2007)       drama    \n",
       "\n",
       "                                         DESCRIPTION  \n",
       "0   Listening in to a conversation between his do...  \n",
       "1   A brother and sister with a past incestuous r...  \n",
       "2   As the bus empties the students for their fie...  \n",
       "3   To help their unemployed father make ends mee...  \n",
       "4   The film's title refers not only to the un-re...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train data\n",
    "train_data = pd.read_csv('C:\\\\Users\\\\Eyosi\\\\Downloads\\\\Genre Classification Dataset\\\\train_data.txt', delimiter=':::', engine='python', header=None, names=['ID', 'TITLE', 'GENRE', 'DESCRIPTION'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Edgar's Lunch (1998)</td>\n",
       "      <td>L.R. Brane loves his life - his car, his apar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>La guerra de pap치 (1977)</td>\n",
       "      <td>Spain, March 1964: Quico is a very naughty ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Off the Beaten Track (2010)</td>\n",
       "      <td>One year in the life of Albin and his family ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meu Amigo Hindu (2015)</td>\n",
       "      <td>His father has died, he hasn't spoken with hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Er nu zhai (1955)</td>\n",
       "      <td>Before he was known internationally as a mart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                          TITLE  \\\n",
       "0   1          Edgar's Lunch (1998)    \n",
       "1   2      La guerra de pap치 (1977)    \n",
       "2   3   Off the Beaten Track (2010)    \n",
       "3   4        Meu Amigo Hindu (2015)    \n",
       "4   5             Er nu zhai (1955)    \n",
       "\n",
       "                                         DESCRIPTION  \n",
       "0   L.R. Brane loves his life - his car, his apar...  \n",
       "1   Spain, March 1964: Quico is a very naughty ch...  \n",
       "2   One year in the life of Albin and his family ...  \n",
       "3   His father has died, he hasn't spoken with hi...  \n",
       "4   Before he was known internationally as a mart...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "test_data = pd.read_csv('C:\\\\Users\\\\Eyosi\\\\Downloads\\\\Genre Classification Dataset\\\\test_data.txt', delimiter=':::', engine='python', header=None, names=['ID', 'TITLE', 'DESCRIPTION'])\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>GENRE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Edgar's Lunch (1998)</td>\n",
       "      <td>thriller</td>\n",
       "      <td>L.R. Brane loves his life - his car, his apar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>La guerra de pap치 (1977)</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Spain, March 1964: Quico is a very naughty ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Off the Beaten Track (2010)</td>\n",
       "      <td>documentary</td>\n",
       "      <td>One year in the life of Albin and his family ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meu Amigo Hindu (2015)</td>\n",
       "      <td>drama</td>\n",
       "      <td>His father has died, he hasn't spoken with hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Er nu zhai (1955)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Before he was known internationally as a mart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                          TITLE          GENRE  \\\n",
       "0   1          Edgar's Lunch (1998)       thriller    \n",
       "1   2      La guerra de pap치 (1977)         comedy    \n",
       "2   3   Off the Beaten Track (2010)    documentary    \n",
       "3   4        Meu Amigo Hindu (2015)          drama    \n",
       "4   5             Er nu zhai (1955)          drama    \n",
       "\n",
       "                                         DESCRIPTION  \n",
       "0   L.R. Brane loves his life - his car, his apar...  \n",
       "1   Spain, March 1964: Quico is a very naughty ch...  \n",
       "2   One year in the life of Albin and his family ...  \n",
       "3   His father has died, he hasn't spoken with hi...  \n",
       "4   Before he was known internationally as a mart...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data solution\n",
    "test_data_solution = pd.read_csv('C:\\\\Users\\\\Eyosi\\\\Downloads\\\\Genre Classification Dataset\\\\test_data_solution.txt', delimiter=':::', engine='python', header=None, names=['ID', 'TITLE', 'GENRE', 'DESCRIPTION'])\n",
    "test_data_solution.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong> Here, we select which column of the data we use</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "train_X = train_data['DESCRIPTION']\n",
    "train_y = train_data['GENRE']\n",
    "test_X = test_data['DESCRIPTION']\n",
    "test_y = test_data_solution['GENRE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we know, We are trying to extract features from a text data so we use a lemmatizer to ignore the unnecessary parts of the text. We have pretrained model for the English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Data Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And here, we use a function called tokienizer whose job iks to extract repeated words from the plot summary, changes them into array and create a common feature from the generes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize function using NLTK\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>Training the data</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_processed = train_X.apply(preprocess_text)\n",
    "test_X_processed = test_X.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong> Changing the word features into vectors</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize, max_features=5000, stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fitting the data into our trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eyosi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Vectorize train and test data\n",
    "train_X_vec = vectorizer.fit_transform(train_X)\n",
    "test_X_vec = vectorizer.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>Here, We use naive bayes classifier</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(train_X_vec, train_y)\n",
    "nb_predictions = nb_classifier.predict(test_X_vec)\n",
    "nb_accuracy = accuracy_score(test_y, nb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>Here, We use logestic regression classifier</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eyosi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(train_X_vec, train_y)\n",
    "lr_predictions = lr_classifier.predict(test_X_vec)\n",
    "lr_accuracy = accuracy_score(test_y, lr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>Here, We use Support vector machine classifier</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eyosi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines Classifier\n",
    "svm_classifier = LinearSVC()\n",
    "svm_classifier.fit(train_X_vec, train_y)\n",
    "svm_predictions = svm_classifier.predict(test_X_vec)\n",
    "svm_accuracy = accuracy_score(test_y, svm_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>Here, We use AdaBoost classifier</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Classifier\n",
    "ada_classifier = AdaBoostClassifier(n_estimators=500)  \n",
    "ada_classifier = AdaBoostClassifier(learning_rate=0.1)  # Adjust the learning rate\n",
    "ada_classifier.fit(train_X_vec, train_y)\n",
    "ada_predictions = ada_classifier.predict(test_X_vec)\n",
    "ada_accuracy = accuracy_score(test_y, ada_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>Here, We use Random forest classifier</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_classifier.fit(train_X_vec, train_y)\n",
    "rf_predictions = rf_classifier.predict(test_X_vec)\n",
    "rf_accuracy = accuracy_score(test_y, rf_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now' let's compare the accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.5203874538745388\n",
      "Logistic Regression Accuracy: 0.5829151291512915\n",
      "Support Vector Machines Accuracy: 0.5736531365313653\n",
      "AdaBoost Accuracy: 0.3263837638376384\n",
      "Random foresr accuracy: 0.4958671586715867\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Support Vector Machines Accuracy:\", svm_accuracy)\n",
    "print(\"AdaBoost Accuracy:\", ada_accuracy)\n",
    "print(\"Random foresr accuracy:\",rf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see here, the highest accuracy was computed by logestic regression. But, the accuracies are not suitable. So we have to use feature engineering next time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong>THANK YOU!</strong>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
